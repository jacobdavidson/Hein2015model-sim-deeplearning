#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Feb 14 13:56:46 2017

@author: jdavidson
"""

import numpy as np
import matplotlib.pyplot as plt
import random

# Keras things
from keras.models import Sequential
from keras.layers import Input, Dense, Lambda, Flatten, Reshape
from keras.models import Model
from keras.layers import Merge, merge

from keras import backend as K
import tensorflow as tf



# to make it print the whole numpy array
np.set_printoptions(threshold=np.inf)


#%%
#Import saved simulation data and set parameters
# This is the same as train_network3.py

# params
numsims=8  # keep this at 1 or 2 here, because I'm loading it all at once
maxsteps=(200*20)  #200*20
numparticles=100
kmax=25
lmax=25

numpixels=41 # make this an odd number!  

# make list of filenames for these simulations
rnfiles=[("sim"+str(y)+"-"+str(x)+".rn"+".npy") for y in range(numsims) for x in range(1,maxsteps)]
iofiles=[("sim"+str(y)+"-"+str(x)+".io"+".npy") for y in range(numsims) for x in range(1,maxsteps)]
savedir="/home/jdavidson/Documents/py/Hein2015simdata/"
# shuffle the filenames
c = list(zip(rnfiles, iofiles))
random.shuffle(c)
rnfiles, iofiles = zip(*c)

def ToImage(rnsingle,numpixels):
    imgarray=np.zeros([numpixels,numpixels])            
    neighbors=rnsingle
    neighbors=neighbors[neighbors[:,2]<2*lmax]   
    img=np.transpose([np.rint(neighbors[:,0]/(2*lmax)*(numpixels-1))+(numpixels-1)/2, 
                              np.rint(neighbors[:,1]/(2*lmax)*(numpixels-1))+(numpixels-1)/2])
    img=img.astype(int)
    imgarray[img[:,0],img[:,1]] = 1     
    return imgarray


def LoadBatch(batch_size,startpointer,numpixels):
    # batch_size is the number of time steps to load, not the number of individual inferences
#    x_out=np.empty([numparticles*batch_size,kmax,3])
    img_out=np.empty([numparticles*batch_size,numpixels,numpixels])
    s_out=np.empty([numparticles*batch_size])
    y_out=np.empty([numparticles*batch_size,2])
    for i in range(batch_size):
        rn=np.load(savedir+rnfiles[startpointer+i])
        imgs=list(map(lambda x: ToImage(x,numpixels),rn))
        io=np.load(savedir+iofiles[startpointer+i])
       # x_out[i*numparticles:(i+1)*numparticles]=rn
        img_out[i*numparticles:(i+1)*numparticles]=imgs
        s_out[i*numparticles:(i+1)*numparticles]=io[0,:]
        y_out[i*numparticles:(i+1)*numparticles,:]=np.transpose(io[1:3,:]) # delta s, delta a
    return img_out, s_out, y_out

def atan2(y, x, epsilon=1.0e-12):
    # taken from:  https://github.com/tensorflow/tensorflow/issues/6095
    # Add a small number to all zeros, to avoid division by zero:
    x = tf.select(tf.equal(x, 0.0), x+epsilon, x)
    y = tf.select(tf.equal(y, 0.0), y+epsilon, y)

    angle = tf.select(tf.greater(x,0.0), tf.atan(y/x), tf.zeros_like(x))
    angle = tf.select(tf.logical_and(tf.less(x,0.0),  tf.greater_equal(y,0.0)), tf.atan(y/x) + np.pi, angle)
    angle = tf.select(tf.logical_and(tf.less(x,0.0),  tf.less(y,0.0)), tf.atan(y/x) - np.pi, angle)
    angle = tf.select(tf.logical_and(tf.equal(x,0.0), tf.greater(y,0.0)), 0.5*np.pi * tf.ones_like(x), angle)
    angle = tf.select(tf.logical_and(tf.equal(x,0.0), tf.less(y,0.0)), -0.5*np.pi * tf.ones_like(x), angle)
    angle = tf.select(tf.logical_and(tf.equal(x,0.0), tf.equal(y,0.0)), tf.zeros_like(x), angle)
    return angle 

# create training and validation set indices
num=(maxsteps-1)*numsims
allsteps=list(range(num))
trainsteps=allsteps[:int(num * 0.995)]
valsteps=allsteps[-int(num * 0.005):]
print(len(valsteps))

#%% import all the data.  NOTE!  next version of this will uses batches and not load all of it
#imgdata, sdata, ydata = LoadBatch(len(trainsteps),trainsteps[0],numpixels)
#imgdata, sdata, ydata = LoadBatch(len(valsteps),valsteps[0],numpixels)

#%% define loss computation
def lossdiff(x,y):
    return tf.reduce_mean(tf.square(tf.subtract(x,y)))
    
def lossboth(sa_in,sa_out):
    return lossdiff(sa_in[0],sa_out[0])+lossdiff(sa_in[1],sa_out[1])


#%% Define model
flatlength=numpixels*numpixels
input_img = Input(shape=(flatlength,))
input_speed=Input(shape=(1,))
ref_ds=Input(shape=(1,))
ref_da=Input(shape=(1,))
hlayer=Dense(flatlength, activation='relu')(input_img)
hlayer=Dense(flatlength, activation='linear')(hlayer)
GX=Dense(1,activation='linear')(hlayer*input_img)
GY=Dense(1,activation='linear')(hlayer*input_img)

# speed processing
GS=Dense(1,activation='linear')(input_speed*input_speed)
              
# change in X and Y velocities
DVY=GY
xinput=merge([GX,GS], mode='concat', concat_axis=1)  # Merge is for layers, merge is for tensors. This is in the docs...(apparently)
DVX=Dense(1,activation='linear')(xinput)

# Speed and Angle calc
ds_output = K.sqrt(K.square(input_speed+DVX)+K.square(DVY)) - input_speed
da_output = atan2(DVY,input_speed+DVX)


# This doesn't work, because I mix in the Tensorflow calcs!  I don't know how to go around it
# the use of merge(), ad tf.select() are the problems
#modelcalc = Model(input=input_img, output=[)
#sgd=SGD(lr=0.1)
#modelcalc.compile(loss=lossboth, optimizer=SGD)


#%% Back to tensorflow for training
loss = lossdiff(ds_output,ref_ds) + lossdiff(da_output,ref_da)
optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)

  
epochs = 30  #  orignal value is epochs=30
batch_size = 20
val_batch_size = len(valsteps)


sess = tf.InteractiveSession()
sess.run(   tf.global_variables_initializer())
print("session started")
#with tf.Session() as session: #Create graph session
 
# train over the dataset
for epoch in range(epochs):  # this goes through everything in the dataset
  for i in range(int(len(trainsteps)/batch_size)):
    print(i)
    loadpointer = batch_size*i
    #loadpointer = trainsteps[np.random.randint(len(trainsteps)-batch_size-1)]
    imgdata, sdata, ydata = LoadBatch(batch_size,loadpointer,numpixels)
    imgdata=np.reshape(imgdata,(len(imgdata),numpixels*numpixels))
    sdata=np.reshape(sdata,(len(sdata),1))
    outds=np.reshape(ydata[:,0],(len(sdata),1))
    outda=np.reshape(ydata[:,1],(len(sdata),1))
    optimizer.run(feed_dict={input_img: imgdata, input_speed: sdata, ref_ds: outds, ref_da: outda})
    if i % 100 == 1:
      imgdata, sdata, ydata = LoadBatch(val_batch_size,valsteps[0],numpixels)
      imgdata=np.reshape(imgdata,(len(imgdata),numpixels*numpixels))
      sdata=np.reshape(sdata,(len(sdata),1))
      outds=np.reshape(ydata[:,0],(len(sdata),1))
      outda=np.reshape(ydata[:,1],(len(sdata),1)) 
      feed = feed_dict={input_img: imgdata, input_speed: sdata, ref_ds: outds, ref_da: outda}
      loss_value = sess.run(loss, feed_dict=feed)          
      print("Epoch: %d, Step: %d, Loss: %g" % (epoch, epoch * batch_size + i, loss_value))
      
      [validdscalc,validdacalc] = sess.run([ds_output,da_output],feed_dict=feed)
#          validdscalc = model.ds_output.eval(feed_dict=feed)
#          validdacalc = model.da_output.eval(feed_dict=feed)          

      validdsreal = ydata[:,0]
      validdareal = ydata[:,1]
      
      fig = plt.figure(1)  
      fig.clf()
      xyrange=0.2
      ax = fig.add_subplot(121)
      scatter, = ax.plot(validdsreal,validdscalc,'bo')
      plt.xlabel('Simulated')
      plt.ylabel('Model')
      plt.title('Delta speed')
      ax.set_xlim(-xyrange, xyrange)
      ax.set_ylim(-xyrange, xyrange)
      ax.plot([-1,1],[-1,1])
      ax = fig.add_subplot(122)
      scatter, = ax.plot(validdareal,validdacalc,'bo')
      plt.xlabel('Simulated')
      plt.ylabel('Model')
      plt.title('Delta angle')
      ax.set_xlim(-xyrange, xyrange)
      ax.set_ylim(-xyrange, xyrange)
      ax.plot([-1,1],[-1,1])
      plt.show
      plt.pause(0.001)
